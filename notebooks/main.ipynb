{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Time Series Regression Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Business Understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Problem Statement**:\n",
    "\n",
    "The growing need for competitive markets demands efficient use of data for informed decision-making and forecasting. Corporation Favorita, a grocery retailer in Ecuador, seeks to optimize its business strategies by utilizing time series regression analysis. The objective of this project is to develop a robust predictive model that accurately forecasts unit sales based on historical data, including factors such as promotions and other variables. Through understanding temporal patterns and relationships between variables, the goal is to enhance the accuracy of sales predictions and provide actionable insights for strategic decision-making.\n",
    "\n",
    "##### **Goals and Objectives**:\n",
    "\n",
    "1. Develop and build time series regression models including SARIMA, ARIMA, XGBoost, and Linear Regression to accurately forecast unit sales and capture sales data seasonality and trends.\n",
    "\n",
    "2. Evaluate the model's performance using appropriate evaluation metrics such as mean squared error, mean absolute error, and R-squared.\n",
    "\n",
    "3. Provide actionable insights for strategic decision-making, such as identifying promotions or offering targeted marketing strategies.\n",
    "Build time series regression models like SARIMA, ARIMA, XGBoost, and Linear Regression to capture sales data seasonality and trends.\n",
    "\n",
    "##### **Stakeholders**\n",
    "•\tFavorita Company Executives and Management\n",
    "\n",
    "•\tData Science and Analytics Team\n",
    "\n",
    "•\tStore customer service and management teams\n",
    "\n",
    "•\tMarketing and Sales and Advertisement Teams:\n",
    "\n",
    "•\tFinance\n",
    "\n",
    "**Success Criteria**\n",
    "- Achieve a 0.2 RMSE (Root Mean Squared Error) in sales forecasting models.\n",
    "- Improve inventory management efficiency and reduce stockout instances.\n",
    "\n",
    "\n",
    "**Data Requirements**\n",
    "- Utilize data from train.csv, stores.csv, holidays_events.csv, oil.csv, and transaction.csv for analysis.\n",
    "- Include features such as store_nbr, family, onpromotion, store metadata, oil prices, holidays, and transactional data.\n",
    "\n",
    "**Business Impact**\n",
    "- Enhance customer satisfaction through better product availability.\n",
    "- Optimize inventory management, leading to cost savings and improved operational efficiency.\n",
    "\n",
    "##### **Hypothesis** \n",
    "Null Hypothesis (Ho): Holidays do not significantly affect sales at Corporation Favorita's grocery stores.\n",
    "\n",
    "Alternative Hypothesis (Ha): Holidays have a significant impact on sales at Corporation Favorita's grocery stores.\n",
    "\n",
    "##### **Analytical Questions**\n",
    "1. Is the train dataset complete (has all the required dates)?\n",
    "\n",
    "2. Which dates have the lowest and highest sales for each year (excluding days the store was closed)?\n",
    "\n",
    "3. Compare the sales for each month across the years and determine which month of which year had the highest sales.\n",
    "\n",
    "4. Did the earthquake impact sales?\n",
    "\n",
    "5. Are certain stores or groups of stores selling more products? (Cluster, city, state, type)\n",
    "\n",
    "6. Are sales affected by promotions, oil prices and holidays?\n",
    "\n",
    "7. What analysis can we get from the date and its extractable features?\n",
    "\n",
    "8. Which product family and stores did the promotions affect.\n",
    "\n",
    "9. What is the difference between RMSLE, RMSE, MSE (or why is the MAE greater than all of them?)\n",
    "\n",
    "10. Does the payment of wages in the public sector on the 15th and last days of the month influence the store sales.\n",
    "\n",
    "##### **Scope and Constraint**:\n",
    "- Assumption: Historical sales data is representative of future demand patterns.\n",
    "- Constraint: Limited availability of real-time sales data for model training.\n",
    "\n",
    "\n",
    "#### Additional Information\n",
    "\n",
    "This project is to be completed in 4 weeks \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Understanding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Importation of libraries**\n",
    " #Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# Database connectivity\n",
    "import pyodbc\n",
    " \n",
    "# Database ORM (optional)\n",
    "from sqlalchemy import create_engine\n",
    " \n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "\n",
    "# Machine learning \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Database connectivity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10840\\1327232234.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_oil = pd.read_sql(query_oil, conn)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10840\\1327232234.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_holidays_events = pd.read_sql(query_holidays_events, conn)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10840\\1327232234.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_stores = pd.read_sql(query_stores, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oil Data:\n",
      "         date  dcoilwtico\n",
      "0  2013-01-01         NaN\n",
      "1  2013-01-02   93.139999\n",
      "2  2013-01-03   92.970001\n",
      "3  2013-01-04   93.120003\n",
      "4  2013-01-07   93.199997\n",
      "\n",
      "Holidays Events Data:\n",
      "         date     type    locale locale_name                    description  \\\n",
      "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
      "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
      "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
      "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
      "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
      "\n",
      "   transferred  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n",
      "\n",
      "Stores Data:\n",
      "   store_nbr           city                           state type  cluster\n",
      "0          1          Quito                       Pichincha    D       13\n",
      "1          2          Quito                       Pichincha    D       13\n",
      "2          3          Quito                       Pichincha    D        8\n",
      "3          4          Quito                       Pichincha    D        9\n",
      "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4\n"
     ]
    }
   ],
   "source": [
    "#Connecting to the first databases\n",
    "\n",
    "# Define the connection string\n",
    "server = 'dap-projects-database.database.windows.net'\n",
    "database = 'dapDB'\n",
    "username = 'learning_project_3'\n",
    "password = 'A$uB1Lp3$2@24'\n",
    "conn_str = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "\n",
    "# Connect to the database\n",
    "conn = pyodbc.connect(conn_str)\n",
    "print(\"Connection successful\")\n",
    "\n",
    "# Queries to retrieve data from the three tables\n",
    "query_oil = 'SELECT * FROM dbo.oil'\n",
    "query_holidays_events = 'SELECT * FROM dbo.holidays_events'\n",
    "query_stores = 'SELECT * FROM dbo.stores'\n",
    "\n",
    "# Execute the queries and fetch the data into pandas DataFrames\n",
    "df_oil = pd.read_sql(query_oil, conn)\n",
    "df_holidays_events = pd.read_sql(query_holidays_events, conn)\n",
    "df_stores = pd.read_sql(query_stores, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "print(\"Oil Data:\")\n",
    "print(df_oil.head())\n",
    "\n",
    "print(\"\\nHolidays Events Data:\")\n",
    "print(df_holidays_events.head())\n",
    "\n",
    "print(\"\\nStores Data:\")\n",
    "print(df_stores.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id        date  store_nbr      family  onpromotion\n",
      "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
      "1  3000889  2017-08-16          1   BABY CARE            0\n",
      "2  3000890  2017-08-16          1      BEAUTY            2\n",
      "3  3000891  2017-08-16          1   BEVERAGES           20\n",
      "4  3000892  2017-08-16          1       BOOKS            0\n"
     ]
    }
   ],
   "source": [
    "# Connecting to the test database\n",
    "\n",
    "# File path of the CSV file\n",
    "file_path = r\"C:\\Users\\USER\\Desktop\\test.csv\"\n",
    "\n",
    "# Load CSV file into a DataFrame\n",
    "Test_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(Test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  sales\n",
      "0  3000888    0.0\n",
      "1  3000889    0.0\n",
      "2  3000890    0.0\n",
      "3  3000891    0.0\n",
      "4  3000892    0.0\n"
     ]
    }
   ],
   "source": [
    "#connecting to sample submission database\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# File path of the CSV file\n",
    "file_path = r\"C:\\Users\\USER\\Desktop\\sample_submission.csv\"\n",
    "\n",
    "# Load CSV file into a DataFrame\n",
    "sample_submission_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(sample_submission_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exploratory Data Analysis (EDA)**\n",
    "\n",
    "- Data Quality Assement ,EDA & Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1218 entries, 0 to 1217\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        1218 non-null   object \n",
      " 1   dcoilwtico  1175 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 19.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#checking basic info for df_oil data \n",
    "\n",
    "df_oil.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 350 entries, 0 to 349\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         350 non-null    object\n",
      " 1   type         350 non-null    object\n",
      " 2   locale       350 non-null    object\n",
      " 3   locale_name  350 non-null    object\n",
      " 4   description  350 non-null    object\n",
      " 5   transferred  350 non-null    bool  \n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 14.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#checking basic info for df_holidays_events data\n",
    "\n",
    "df_holidays_events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54 entries, 0 to 53\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   store_nbr  54 non-null     int64 \n",
      " 1   city       54 non-null     object\n",
      " 2   state      54 non-null     object\n",
      " 3   type       54 non-null     object\n",
      " 4   cluster    54 non-null     int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#checking basic info for df_stores data\n",
    "\n",
    "df_stores.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Insights from column\n",
    "\n",
    "Oil Data\n",
    "1. df_oil has 19691 rows and 2 columns, with no missing values. The 'Date' column is in 'object' format, which needs to be converted to 'datetime'.\n",
    "2. Daily oil prices (dcoilwtico) are recorded over time.\n",
    "\n",
    "Data Type Changes Needed:\n",
    "\n",
    "1. The date column must be converted to a datetime format for easier time series analysis.\n",
    "2. Ensure dcoilwtico is in a numerical format (float) for numerical operations.\n",
    "\n",
    "Holidays Events Data\n",
    "\n",
    "1. df_holidays_events has 1115 rows and 11 columns, with no missing values. The 'date' column is in 'object' format, which needs to be converted to 'datetime'. The 'type' column has 10 unique categories.\n",
    "2. Records various types of holidays and events across different locales.\n",
    "3. Observing if a holiday was transferred to another date (transferred column).\n",
    "\n",
    "\n",
    "- Convert date to datetime format for consistency.\n",
    "\n",
    "- Team must ensure type, locale, locale_name, description are categorical variables or strings.\n",
    "\n",
    "- Check for null values in city, state, type, and cluster columns, though this typically depends on data quality.\n",
    "Data Type Changes Needed:\n",
    "\n",
    "- Convert store_nbr and cluster to categorical variables if they represent categories rather than numerical values.\n",
    "\n",
    "- Ensure city, state, type are categorical variables or strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>93.139999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>92.970001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>93.120003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>93.199997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  dcoilwtico type locale locale_name description transferred  \\\n",
       "0  2013-01-01         NaN  NaN    NaN         NaN         NaN         NaN   \n",
       "1  2013-01-02   93.139999  NaN    NaN         NaN         NaN         NaN   \n",
       "2  2013-01-03   92.970001  NaN    NaN         NaN         NaN         NaN   \n",
       "3  2013-01-04   93.120003  NaN    NaN         NaN         NaN         NaN   \n",
       "4  2013-01-07   93.199997  NaN    NaN         NaN         NaN         NaN   \n",
       "\n",
       "   store_nbr city state  cluster  \n",
       "0        NaN  NaN   NaN      NaN  \n",
       "1        NaN  NaN   NaN      NaN  \n",
       "2        NaN  NaN   NaN      NaN  \n",
       "3        NaN  NaN   NaN      NaN  \n",
       "4        NaN  NaN   NaN      NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate df_oil, df_holidays_events, and df_stores into one DataFrame\n",
    "\n",
    "combined_data = pd.concat([df_oil, df_holidays_events, df_stores], axis=0)\n",
    "\n",
    "#show the first few rows of the combined DataFrame\n",
    "\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1622 entries, 0 to 53\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   date         1568 non-null   object \n",
      " 1   dcoilwtico   1175 non-null   float64\n",
      " 2   type         404 non-null    object \n",
      " 3   locale       350 non-null    object \n",
      " 4   locale_name  350 non-null    object \n",
      " 5   description  350 non-null    object \n",
      " 6   transferred  350 non-null    object \n",
      " 7   store_nbr    54 non-null     float64\n",
      " 8   city         54 non-null     object \n",
      " 9   state        54 non-null     object \n",
      " 10  cluster      54 non-null     float64\n",
      "dtypes: float64(3), object(8)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#check basic info for combined_data data\n",
    "\n",
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             54\n",
       "dcoilwtico      447\n",
       "type           1218\n",
       "locale         1272\n",
       "locale_name    1272\n",
       "description    1272\n",
       "transferred    1272\n",
       "store_nbr      1568\n",
       "city           1568\n",
       "state          1568\n",
       "cluster        1568\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "\n",
    "combined_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying the number of unique stores\n",
    "\n",
    "len(combined_data['store_nbr'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1568</td>\n",
       "      <td>404</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1346</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2014-06-25</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Carnaval</td>\n",
       "      <td>False</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>221</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>10</td>\n",
       "      <td>338</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date     type    locale locale_name description transferred  \\\n",
       "count         1568      404       350         350         350         350   \n",
       "unique        1346       11         3          24         103           2   \n",
       "top     2014-06-25  Holiday  National     Ecuador    Carnaval       False   \n",
       "freq             5      221       174         174          10         338   \n",
       "\n",
       "         city      state  \n",
       "count      54         54  \n",
       "unique     22         16  \n",
       "top     Quito  Pichincha  \n",
       "freq       18         19  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe the categorical variables in combined_data\n",
    "\n",
    "combined_data.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dcoilwtico</th>\n",
       "      <td>1175.0</td>\n",
       "      <td>67.714366</td>\n",
       "      <td>25.630476</td>\n",
       "      <td>26.190001</td>\n",
       "      <td>46.405001</td>\n",
       "      <td>53.189999</td>\n",
       "      <td>95.66</td>\n",
       "      <td>110.620003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <td>54.0</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>15.732133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>40.75</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <td>54.0</td>\n",
       "      <td>8.481481</td>\n",
       "      <td>4.693395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>13.00</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count       mean        std        min        25%        50%  \\\n",
       "dcoilwtico  1175.0  67.714366  25.630476  26.190001  46.405001  53.189999   \n",
       "store_nbr     54.0  27.500000  15.732133   1.000000  14.250000  27.500000   \n",
       "cluster       54.0   8.481481   4.693395   1.000000   4.000000   8.500000   \n",
       "\n",
       "              75%         max  \n",
       "dcoilwtico  95.66  110.620003  \n",
       "store_nbr   40.75   54.000000  \n",
       "cluster     13.00   17.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe the numerical variables in combined_data\n",
    "\n",
    "combined_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           1346\n",
       "dcoilwtico      998\n",
       "type             11\n",
       "locale            3\n",
       "locale_name      24\n",
       "description     103\n",
       "transferred       2\n",
       "store_nbr        54\n",
       "city             22\n",
       "state            16\n",
       "cluster          17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for unique values in combined_data\n",
    "\n",
    "combined_data.nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
